# Crawler-and-pdf-parser
Como usar a spider:  
-instalar o scrapy com "conda install -c conda-forge scrapy" ou "pip install Scrapy"  
-iniciar um projeto scrapy com "scrapy startproject spider"  
-substituir os arquivos do projeto com os do repositorio  
-navegar até o diretorio do codigo pdfdownloader no terminal  
-rodar o codigo com o comando "scrapy crawl (nome da spider a ser utilizada sem parenteses)"  

no codigo pdfdownloader existem varias diferentes spiders para sites diferentes, cada uma delas tem uma variavel name, essa variavel é o nome para ser utilizado no comando de rodar a spider. exemplo: scrapy crawl sbcm  

Repositorios de pdf adicionados: anppom
                                 sbcm
                                 opus
                                 permusi
                                 abem
                                 hodie
                                 orfeu
                                 revistamusica
